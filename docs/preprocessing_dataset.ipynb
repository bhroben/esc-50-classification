{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "from audiomentations import AddGaussianSNR,PitchShift, Compose,AddGaussianNoise,TimeStretch,Shift\n",
    "import tensorflow as tf\n",
    "import data_utils as du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_resample_aug(csv,input_path,output_path,sample_rate=16000, repeat=1,transform=None,df_aug_name='esc50_augmented.csv'):\n",
    "    \"\"\"\n",
    "    Preprocess and resample audio files, with optional augmentation transformations.\n",
    "\n",
    "    Args:\n",
    "        csv (str): Path to the CSV file containing metadata of audio files.\n",
    "        input_path (str): Path to the directory containing the original audio files.\n",
    "        output_path (str): Path to the directory where preprocessed audio files will be saved.\n",
    "        sample_rate (int, optional): Sampling rate for the audio files. Default is 16000.\n",
    "        repeat (int, optional): Number of times to repeat the augmentation. Default is 1.\n",
    "        transform (callable, optional): Transformation function to apply to the audio files. Default is None.\n",
    "        df_aug_name (str, optional): Name of the CSV file to save metadata of augmented audio files. Default is 'esc50_augmented.csv'.\n",
    "    \"\"\"\n",
    "\n",
    "    #read the csv file\n",
    "    df=pd.read_csv(csv)\n",
    "    \n",
    "     #if folder exists, delete it\n",
    "    if os.path.exists(output_path):\n",
    "        shutil.rmtree(output_path)\n",
    "\n",
    "    #iterate over the rows in the csv file\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    \n",
    "    if transform:\n",
    "        df_aug=df.copy() #create a copy of the dataframe to add the augmented files\n",
    "\n",
    "\n",
    "    for index, row in tqdm(df.iterrows()):\n",
    "\n",
    "        if transform:\n",
    "            y,_=librosa.load(input_path+row['filename'], sr=sample_rate)\n",
    "\n",
    "            # augmentation\n",
    "            for i in range(repeat):\n",
    "\n",
    "                augmented_sound = transform(y, sample_rate=sample_rate)\n",
    "                sf.write(output_path+str(i)+'__'+row['filename'], augmented_sound, sample_rate)\n",
    "                #add the augmented file to the dataframe with the same columns\n",
    "                df_aug.loc[len(df_aug)]=df.loc[index]\n",
    "                df_aug.loc[len(df_aug)-1,'filename']=str(i)+'__'+row['filename']\n",
    "\n",
    "                if i==0:\n",
    "                    sf.write(output_path+row['filename'], y, sample_rate)\n",
    "    \n",
    "        else:\n",
    "            y,_=librosa.load(input_path+row['filename'], sr=sample_rate)\n",
    "            sf.write(output_path+row['filename'], y, sample_rate)\n",
    "\n",
    "    if transform:\n",
    "        df_aug.to_csv(output_path+df_aug_name,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio augmentation transformations\n",
    "transform = Compose([\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "    TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "    PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
    "    Shift(min_shift=-0.5, max_shift=0.5, p=0.5),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [01:45, 19.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# first dataset without augmentation: only resampling to 16k, total of 2000 files\n",
    "preprocessing_resample_aug(csv='/mnt/ESC-50-master/meta/esc50.csv',\n",
    "                input_path= '/mnt/ESC-50-master/audio/',\n",
    "                output_path='/mnt/ESC-50-master/audio_16k/',\n",
    "                sample_rate=16000,\n",
    "                repeat=0,\n",
    "                transform=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [09:02,  3.69it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# second dataset with augmentation: resampling to 16k and augmentation with repeat=4, total of 10000 files\n",
    "preprocessing_resample_aug(csv='/mnt/ESC-50-master/meta/esc50.csv',\n",
    "                input_path= '/mnt/ESC-50-master/audio/',\n",
    "                 output_path='/mnt/ESC-50-master/audio_16k_aug_r4/',\n",
    "                    sample_rate=16000,\n",
    "                    repeat=4,\n",
    "                     transform=transform,\n",
    "                     df_aug_name='esc50_augmented_r4.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aug=pd.read_csv('/mnt/ESC-50-master/audio_16k_aug_r4/esc50_augmented_r4.csv')\n",
    "len(df_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Deprecated function\n",
    "#previous function to preprocess the data with augmentation and split into train and validation folders\n",
    "\n",
    "\n",
    "def prepreprocessing_with_folders(csv_file,audio_dir,save_dir,freq=16000,val_split=0.2, transform=transform,repeat=1):\n",
    "    \"\"\"\n",
    "    This function takes a csv file with the following columns: filename, fold, category, esc10, src_file, take\n",
    "    and the audio directory where the audio files are stored. It then splits the data into train and validation\n",
    "    folders and applies augmentation(augment=True) to the training set. each class is stored in a separate folder.\n",
    "    The augmented files are repeated with the number of times specified in the repeat parameter.\n",
    "    The probability of applying the augmentation is specified in the prob parameter.\n",
    "    repeat = 1 means that the original file is copied once and augmented once.\n",
    "    Parameters:\n",
    "    \"\"\"\n",
    "    audio_data = pd.read_csv(csv_file)\n",
    "    audio_data=audio_data.sample(frac=1).reset_index(drop=True)\n",
    "    grouped = audio_data.groupby('category')\n",
    "\n",
    "\n",
    "\n",
    "    for name,group in tqdm(grouped):\n",
    "        \n",
    "\n",
    "        if name:\n",
    "            if not (os.path.isdir(save_dir+\"train/\"+name) and os.path.isdir(save_dir+\"val/\"+name)):\n",
    "                os.makedirs(save_dir+\"train/\"+name)\n",
    "                os.makedirs(save_dir+\"val/\"+name)   \n",
    "\n",
    "            j=0\n",
    "            for i in group['filename']:\n",
    "                #len of group\n",
    "                len_group = len(group)\n",
    "                y,_ = librosa.load(audio_dir+i, sr=freq)\n",
    "                # copy sample from original dataset into validation with no augmentation\n",
    "                if j<len_group*val_split:\n",
    "                    sf.write(save_dir+\"val/\"+name+'/'+i, y, freq)\n",
    "    \n",
    "                # copy sample from original dataset into train with augmentation\n",
    "                else:\n",
    "                    if transform is not None:\n",
    "                            for k in range(repeat):\n",
    "                                transformed = transform(y, sample_rate=16000)\n",
    "                                sf.write(save_dir+\"train/\"+name+'/'+i[:-4]+str(k)+'.wav', transformed, freq)\n",
    "                                if k == 0:\n",
    "                                    sf.write(save_dir+\"train/\"+name+'/'+i, y, freq) # append also original file\n",
    "                    else:\n",
    "                        sf.write(save_dir+\"train/\"+name+'/'+i, y, freq)\n",
    "                j+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:26<00:00, 12.53s/it]\n"
     ]
    }
   ],
   "source": [
    "prepreprocessing_with_folders('/mnt/ESC-50-master/meta/esc50.csv',\n",
    "                 '/mnt/ESC-50-master/audio/',\n",
    "                 '/mnt/ESC-50-master/audio_aug/',\n",
    "                 freq=16000,val_split=0.3,augment=True, repeat=5,prob=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
